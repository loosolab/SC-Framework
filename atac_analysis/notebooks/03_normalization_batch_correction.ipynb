{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b04638",
   "metadata": {
    "editable": false,
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from sctoolbox.utils.jupyter import bgcolor, _compare_version\n",
    "\n",
    "# change the background of input cells\n",
    "bgcolor(\"PowderBlue\", select=[3, 6, 8, 11, 15, 18, 25, 28])\n",
    "\n",
    "nb_name = \"03_normalization_batch_correction.ipynb\"\n",
    "\n",
    "_compare_version(nb_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf8be50",
   "metadata": {},
   "source": [
    "# 03 - Normalization and Batch effect correction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d3dd8",
   "metadata": {},
   "source": [
    "## 1 - Description\n",
    "\n",
    "Similar to quality control and filtering this step is aimed to prepare the data to facilitate better results in the following analysis steps. However, with normalization and batch effect correction the aim is to refine the data points in a way that\n",
    "\n",
    "1. comparability between e.g. samples is enhanced\n",
    "2. the influence of outliers is mitigated\n",
    "3. variances introduced by technical or otherwise unwanted sources are omitted from the dataset.\n",
    "\n",
    "Since this reduces the overall noise, the embedding and clustering steps in particular benefit from these adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81bef47",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1352490e",
   "metadata": {},
   "source": [
    "## 2 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2459bc13",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "import sctoolbox.tools as tools\n",
    "import sctoolbox.plotting as pl\n",
    "import sctoolbox.utils as utils\n",
    "from sctoolbox import settings\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "settings.settings_from_config(\"config.yaml\", key=\"03\")\n",
    "\n",
    "sc.set_figure_params(vector_friendly=True, dpi_save=600, scanpy=False)\n",
    "\n",
    "with pd.option_context(\"display.max.rows\", None, \"display.max_colwidth\", None):\n",
    "    display(utils.general.get_version_report(report=\"versions.yml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd8863",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7cb1b",
   "metadata": {},
   "source": [
    "## 3 - Load anndata\n",
    "Loads the anndata.h5ad from the last notebook and provides a basic overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7fd4d",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "adata = utils.adata.load_h5ad(\"anndata_2.h5ad\")\n",
    "\n",
    "with pd.option_context(\"display.max.rows\", 5, \"display.max.columns\", None):\n",
    "    display(adata)\n",
    "    display(adata.obs)\n",
    "    display(adata.var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d8b92",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b99e7",
   "metadata": {},
   "source": [
    "## 4 - General input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d5d70",
   "metadata": {},
   "source": [
    "<h1><center>⬐ Fill in input data here ⬎</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f494d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose normalization method\n",
    "# TF-IDF: dimensionality is reduced by LSI\n",
    "# Total: dimensionality is reduced by PCA \n",
    "norm_method = 'tfidf'  # can be 'tfidf' or 'total'\n",
    "\n",
    "# Set number of neighbors\n",
    "n_neighbors = 15\n",
    "\n",
    "# UMAP related settings \n",
    "metacol = 'sample'  # some meta-column of interest. See tables above.\n",
    "n_features = 'n_features'  # column name for the number of features. See tables above.\n",
    "\n",
    "# batch correction: If True, several batch correction methods will be performed,\n",
    "# you can choose the best one after\n",
    "batch_column = \"sample\"\n",
    "perform_batch_correction = True\n",
    "batch_methods = [\"bbknn\", \"harmony\"] # \"mnn\", \"scanorama\", \"combat\" \n",
    "settings.threads = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb7da7",
   "metadata": {},
   "source": [
    "________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7e2c0",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Ensure that the batch column is of type category\n",
    "adata.obs[batch_column] = adata.obs[batch_column].astype(str).astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6839ff17",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab515b",
   "metadata": {},
   "source": [
    "## 5 - Normalization\n",
    "<hr style=\"border:2px solid black\"> </hr>\n",
    "\n",
    "This section performs the selected normalization method followed by a dimension reduction. The counts for each cell are normalized so that all cells have the same number of counts after normalization. This removes imbalances in sequencing depth to make the cells comparable.\n",
    "\n",
    "The normalization method can be either TF-IDF or total count normalization. Term frequency-inverse document frequencies (TF-IDF), initially adopted by search engines, scores each variable (here open chromatin region) by their importance. It compares the frequency of a variable within a cell against the global occurrence over all cells thus highlighting cell defining variables. On the other hand, total count normalization adjusts the total count of each cell so that all cells have the same total count after normalization. A method frequently used for single cell RNA data.\n",
    "\n",
    "After normalization a dimension reduction is computed, which depending on the normalization is either latent semantic indexing (LSI) for TF-IDF or principal component analysis (PCA) for total count. However, while differing in details both reduction methods are analogous and thus the following steps are the same independent of the chosen method. Since TF-IDF has been shown to be particularly effective for ATAC-seq data, it is used here as the default method.  \n",
    "**DOI: [10.1038/nature25981](https://doi.org/10.1038/nature25981)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566415a",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "adata = tools.norm_correct.normalize_adata(adata, norm_method, report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88125d6",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd2b90",
   "metadata": {},
   "source": [
    "## 6 - Find highly variable features\n",
    "<hr style=\"border:2px solid black\"> </hr>\n",
    "\n",
    "Identify features that occur in only a fraction of cells. While the concept is similar to identifying highly variable genes (HVGs) in RNA, ATAC feature count (chromatin accesibility) has to be interpreted differently than RNA gene expression. Thus, we measure the absence of features (`count = 0`) to identify variability instead of count number, as is done with HVGs.\n",
    "\n",
    "### 6.1 - Parameter Overview\n",
    "\n",
    "Try to find the optimal parameter combination using the boundaries below\n",
    "\n",
    "| Parameter | Description | Options |\n",
    "|-----------|-------------|---------|\n",
    "| min_cells | Minimum amount of cells expressing the variable feature. | Default 5 |\n",
    "| max_cells | Maximum amount of cells expressing the variable feature. None to use knee estimated threshold. | Default None |\n",
    "\n",
    "For more information see:\n",
    "\n",
    "https://loosolab.pages.gwdg.de/software/sc_framework/API/tools.html#sctoolbox.tools.highly_variable.get_variable_features\n",
    "\n",
    "https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.highly_variable_genes.html#scanpy-pp-highly-variable-genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly Variable Features options \n",
    "min_cells = 5 # This one is mandatory\n",
    "max_cells = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c14f8",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# get highly variable features\n",
    "tools.highly_variable.get_variable_features(adata, max_cells, min_cells,\n",
    "                                            report=\"01_highly_variable_feature.png\",\n",
    "                                            save=\"highly_variable_feature.pdf\")\n",
    "# plot HVF violin\n",
    "pl.highly_variable.violin_HVF_distribution(adata, save=\"cell_per_highly_variable_feature.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6046d",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d72df3",
   "metadata": {},
   "source": [
    "## 6 - Dimension reduction and neighbor graph\n",
    "<hr style=\"border:2px solid black\"> </hr>\n",
    "Another important property of our data is its high dimensionality. However, this complexity hinders in-depth analysis e.g. the identification of cell states. Thus, dimension reduction algorithms are applied to reduce complexity while simultaneously retaining patterns, a crucial step to enable embedding and clustering. In other words, noise is reduced by removing low variance components as well as components explaining technical or otherwise unwanted factors (e.g. number of active genes, cell cycle, etc.) which also has the benefit of reducing the computational demand. Here the applied algorithms are either Principal Component Analysis (PCA) or Latent Semantic Indexing (LSI). The applied dimension reduction depends on the chosen normalization with total count using PCA and TF-IDF using LSI. For convenience, results of both methods are called principal components (PCs) in the following analysis steps.\n",
    "\n",
    "**DOI: [10.1038/nmeth.4346](https://doi.org/10.1038/nmeth.4346)**  \n",
    "**DOI: [10.1038/nature25981](https://doi.org/10.1038/nature25981)**\n",
    "\n",
    "The following heatmaps and barplots are intended to identify potentially unwanted PCs by showing the PCs in combination with available observations (cell-related metrics) and variables (feature-related metrics). In general, **selected PCs should avoid correlations with metrics**, but the importance of metrics and the stringency of thresholds depends on the experiment and the underlying questions, and therefore requires careful consideration by the analyst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e271a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pcs = 50  # The number of PCs to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63ce08",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "default_pca_color = [k for k in adata.uns[\"sctoolbox\"][\"report\"][\"qc\"][\"obs\"][\"threshold\"].keys() if k not in [\"before\", \"after\"]] + [batch_column]\n",
    "default_pca_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603db609",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "if norm_method == \"tfidf\":\n",
    "    tools.dim_reduction.lsi(adata, n_comps=n_pcs, use_highly_variable=True, report=True)\n",
    "elif norm_method == \"total\":\n",
    "    tools.dim_reduction.compute_PCA(adata, svd_solver='arpack', mask_var=\"highly_variable\", n_comps=n_pcs, inplace=True, report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2713a6a6",
   "metadata": {},
   "source": [
    "<h1><center>⬐ Fill in input data here ⬎</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of PCs shown within the heatmap\n",
    "n_pcs_heatmap = 15\n",
    "\n",
    "pca_color = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aedbf1",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d79f6",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Plot QC variables on the PCA embedding to show potential correlations\n",
    "_ = pl.embedding.plot_embedding(\n",
    "    adata,\n",
    "    method='pca',\n",
    "    color=pca_color if pca_color else default_pca_color,\n",
    "    ncols=3,\n",
    "    suptitle=f\"{'Principle Component Analysis (PCA)' if norm_method == 'total' else 'Latent Semantic Indexing (LSI)'}\\ncolored by quality control metrics\",\n",
    "    report=f\"02_{'PCA' if norm_method == 'total' else 'LSI'}_correlation_2D.png\",\n",
    "    save=f\"{'PCA' if norm_method == 'total' else 'LSI'}_embedding.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f6475",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    " # PCA correlations with obs variables \n",
    "_ = pl.embedding.plot_pca_correlation(\n",
    "    adata,\n",
    "    n_components=n_pcs_heatmap,\n",
    "    which=\"obs\",\n",
    "    title=f\"Correlation of .obs columns with {'PCA' if norm_method == 'total' else 'LSI'} loadings\",\n",
    "    save=\"{'PCA' if norm_method == 'total' else 'LSI'}_correlation_obs.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf369e7",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    " # PCA correlations with var variables\n",
    "_ = pl.embedding.plot_pca_correlation(\n",
    "    adata,\n",
    "    n_components=n_pcs_heatmap,\n",
    "    which=\"var\",\n",
    "    title=f\"Correlation of .var columns with {'PCA' if norm_method == 'total' else 'LSI'} loadings\",\n",
    "    save=f\"{'PCA' if norm_method == 'total' else 'LSI'}_correlation_var.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6470b",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b0d76",
   "metadata": {},
   "source": [
    "### 6.1 - Choose a subset of PCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cfc9cd",
   "metadata": {},
   "source": [
    "In case the above plots showed undesired correlation this section can be used to subset the PCs. The proposed PC subset is displayed as a plot with darker bars representing the selected PCs. Based on the selected `filter_methods`, a vertical and horizontal threshold line is displayed. PCs are filtered if they are below the horizontal threshold (`corr_thresh`) or if they are to the right of the vertical threshold line (`perc_thresh`).\n",
    "\n",
    "| Parameter | Description | Options |\n",
    "|:---:|:---|:---|\n",
    "| subset_pcs | Whether the PCs should be filtered. | `True` or `False` |\n",
    "| corr_thresh | Highest absolute correlation that is allowed. Will take the maximum correlation for each PC as shown in the heatmap above. | Expects a value between `0-1`. |\n",
    "| perc_thresh | Top percentile of PCs that should be kept. | A value between `0-100`%. |\n",
    "| filter_methods | The PCs will be filtered based on the given methods. E.g. for \"variance\" and \"correlation\" PCs are filtered on values from both methods and the intersection is used as the final subset. | Any combination of `[\"variance\", \"cumulative variance\", \"correlation\"]` |\n",
    "| basis | Compute correlation based on observations (cells) or variables (genes). | Either `obs` or `var`. |\n",
    "|ignore_cols| List of column names to ignore for correlation | `None` or a list of column names|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926c215",
   "metadata": {},
   "source": [
    "<h1><center>⬐ Fill in input data here ⬎</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f82b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether PCs should be filtered\n",
    "subset_pcs = True\n",
    "\n",
    "corr_thresh = 0.6  # PCs with an absolut correlation above this will be filtered\n",
    "perc_thresh = 50  # Top percentile of PCs that should be kept\n",
    "filter_methods = ['variance', 'correlation']  # propose PCs based on the provided methods\n",
    "basis = 'obs'  # base correlation on obs or var\n",
    "ignore_cols = []  # List of column names to ignore for correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a515c",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67265f39",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "selected_pcs = tools.dim_reduction.propose_pcs(\n",
    "    anndata=adata,\n",
    "    how=filter_methods,\n",
    "    corr_thresh=corr_thresh,\n",
    "    perc_thresh=perc_thresh,\n",
    "    corr_kwargs={'method': 'spearmanr', 'which': basis, 'ignore': ignore_cols}\n",
    ")\n",
    "\n",
    "# Plot and select number of PCs\n",
    "_ = pl.embedding.plot_pca_variance(\n",
    "    adata, \n",
    "    save=f\"{'PCA' if norm_method == 'total' else 'LSI'}_variance_proposed_selection.pdf\",\n",
    "    selected=selected_pcs,\n",
    "    n_pcs=50,\n",
    "    n_thresh=max(selected_pcs),\n",
    "    corr_plot='spearmanr',\n",
    "    corr_thresh=corr_thresh,\n",
    "    corr_on=basis,\n",
    "    ignore=ignore_cols,\n",
    "    suptitle=f\"{'PCA' if norm_method == 'total' else 'LSI'} Component Selection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dec826",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "f\"Proposed components: {selected_pcs}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba4403",
   "metadata": {},
   "source": [
    "Create a final PC-selection by changing the blue cell below:\n",
    "- Either copy and adjust the proposed list from directly above\n",
    "- create a custom list of PCs\n",
    "- or accept the proposed list by not changing the cell below.\n",
    "\n",
    "**Note: the selection will only be applied when `subset_pcs = True`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e7a1c",
   "metadata": {},
   "source": [
    "<h1><center>⬐ Fill in input data here ⬎</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pc_selection = selected_pcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4bd67a",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd92735",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    " _ = pl.embedding.plot_pca_variance(\n",
    "    adata, \n",
    "    selected=final_pc_selection if subset_pcs else None,\n",
    "    save=f\"{'PCA' if norm_method == 'total' else 'LSI'}_variance_final_selection.pdf\",\n",
    "    n_pcs=50,\n",
    "    n_thresh=max(selected_pcs) if subset_pcs else None,\n",
    "    corr_plot='spearmanr',\n",
    "    corr_thresh=corr_thresh if subset_pcs else None,\n",
    "    corr_on=basis,\n",
    "    ignore=ignore_cols,\n",
    "    report=f\"03_{'PCA' if norm_method == 'total' else 'LSI'}_variance_subset.png\",\n",
    "    suptitle=f\"{'PCA' if norm_method == 'total' else 'LSI'} Component Selection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1cc639",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Subset the number of pcs if chosen in the parameters\n",
    "if subset_pcs:\n",
    "    tools.dim_reduction.subset_PCA(adata, select=final_pc_selection, report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084779da",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadff57d",
   "metadata": {},
   "source": [
    "### 6.2 - Calculate neighbors\n",
    "This step construct a graph connecting the cells with their k-nearest-neighbors based on the selected dimension reduction components. This graph represents the structure of the data and thus is used to detect clusters visualized in the UMAP in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6cd6c",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, n_neighbors=n_neighbors, method='umap', metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1930a",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66fe08e",
   "metadata": {},
   "source": [
    "## 7 - Batch correction\n",
    "<hr style=\"border:2px solid black\"> </hr>\n",
    "\n",
    "Batch effects are variances in the data that are not intended by the experimental design (e.g. technical variance). They can be introduced through various sources. For example, sequencing samples at different timepoints may introduce batch effects. As batch effects could interfere with downstream analysis they are typically removed. However, it can be challenging to identify and correct for batch effects as this is highly dependent on the experimental setup of the dataset.\n",
    "\n",
    "**DOI: [10.1038/nrg2825](https://doi.org/10.1038/nrg2825)**\n",
    "\n",
    "There are several batch correction methods available, which may perform differently depending on the data set. Therefore, an overview is provided to compare batch correction methods and select the best performing one. To help in the decision making process, several metrics are shown that can be selected below and a score (LISI) is provided that explains whether the batches are well mixed after applying the correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef074edc",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "if perform_batch_correction:\n",
    "    # use the options set prior to recompute PCA/ neighbor graph if necessary\n",
    "    shared_kwargs = {\"highly_variable\": True,\n",
    "                     \"dim_red_kwargs\": {\"method_kwargs\": {\"n_comps\": n_pcs},\n",
    "                                        \"subset\": final_pc_selection if subset_pcs else None,\n",
    "                                        \"neighbor_kwargs\": {\"n_neighbors\": n_neighbors}}}\n",
    "    if norm_method == \"total\":\n",
    "        shared_kwargs[\"dim_red_kwargs\"][\"method_kwargs\"][\"svd_solver\"] = \"arpack\"\n",
    "\n",
    "    method_kwargs = {meth: shared_kwargs.copy() for meth in batch_methods}\n",
    "\n",
    "    batch_corrections = tools.norm_correct.wrap_corrections(\n",
    "        adata, \n",
    "        batch_key=batch_column,\n",
    "        methods=batch_methods,\n",
    "        method_kwargs=method_kwargs\n",
    "    )\n",
    "else:\n",
    "    batch_corrections = {\"uncorrected\": adata}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf45a278",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f3791",
   "metadata": {},
   "source": [
    "### 7.1 - Plot overview of batch corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d575554",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Run standard umap for all adatas\n",
    "tools.embedding.wrap_umap(batch_corrections.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2ee9c",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "default_embed_color = [k for k in adata.uns[\"sctoolbox\"][\"report\"][\"qc\"][\"obs\"][\"threshold\"].keys() if k not in [\"before\", \"after\"]] + [batch_column]\n",
    "default_embed_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98a521",
   "metadata": {},
   "source": [
    "<h1><center>⬐ Fill in input data here ⬎</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50187d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should preliminary clustering be performed?\n",
    "do_clustering = True  # True or False\n",
    "\n",
    "# embedding coloring\n",
    "# choose the metrics shown in the following PCA and UMAP\n",
    "# accepts adata.obs column names or genes (adata.var.index)\n",
    "# if empty will use the list shown above\n",
    "embed_color = [batch_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7db29",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f7984e",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Perform additional clustering if it was chosen\n",
    "if do_clustering:\n",
    "    for adata_tmp in batch_corrections.values():\n",
    "        sc.tl.leiden(adata_tmp, resolution=0.1, flavor=\"igraph\", n_iterations=2)\n",
    "    (embed_color if embed_color else default_embed_color).append(\"leiden\")\n",
    "    \n",
    "# Calculate LISI scores for batch\n",
    "tools.norm_correct.wrap_batch_evaluation(batch_corrections, batch_key=batch_column, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b06d2b",
   "metadata": {},
   "source": [
    "**LISI score:**  \n",
    "To determine the strength of a batch effect the Local Inverse Simpson's Index (LISI) can be used by measuring the heterogeneity within a local group. Comparing the LISI score between uncorrected data and the batch correction methods can help in deciding which method performed best.  \n",
    "The LISI score (stored in `adata.obs`) indicates the effective number of different categories represented in the local neighborhood of each cell. If the cells are well-mixed, then we expect the LISI score to be closer to `n` for a dataset with `n` batches.\n",
    "\n",
    "**DOI: [10.1038/s41592-019-0619-0](https://doi.org/10.1038/s41592-019-0619-0)**\n",
    "\n",
    "**The higher the LISI score is, the better the batch correction method worked to normalize the batch effect and mix the cells from different batches.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668cafc4",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Plot the overview of batch correction methods\n",
    "adata.obs[batch_column] = adata.obs[batch_column].astype(\"category\")  # ensure that batch column is a category\n",
    "\n",
    "_ = pl.embedding.anndata_overview(\n",
    "    batch_corrections,\n",
    "    color_by=embed_color if embed_color else default_embed_color,\n",
    "    output=None,\n",
    "    report=\"04_batchcorrections_overview.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a87ff2",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e378503b",
   "metadata": {},
   "source": [
    "<h1><center>⬐ Fill in input data here ⬎</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c7c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an anndata object to proceed\n",
    "selected = \"harmony\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5d8236",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76015510",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "if not perform_batch_correction and selected != \"uncorrected\":\n",
    "    import warnings\n",
    "    warnings.warn(f\"Selected batch correction '{selected}' but batch correction is disabled. Falling back to 'uncorrected'.\")\n",
    "    \n",
    "    selected = \"uncorrected\"\n",
    "elif selected not in batch_corrections:\n",
    "    raise KeyError(f\"'{selected}' is not a key in batch_corrections. Choose one of: {list(batch_corrections.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb3352",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "adata_corrected = batch_corrections[selected]\n",
    "with open(Path(settings.report_dir) / '04_batch_selection.md', 'w') as f: f.write(f\"Selected **{selected}** batch correction method.\")\n",
    "utils.io.update_yaml({\"batch\": selected, \"neighbor_count\": adata_corrected.uns[\"neighbors\"][\"params\"][\"n_neighbors\"]}, yml=\"method.yml\", path_prefix=\"report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a995f37c",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f56dcd",
   "metadata": {},
   "source": [
    "## 8 - Saving adata for the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3739f3c",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "adata_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c110c",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Saving the data\n",
    "adata_output = \"anndata_3.h5ad\"\n",
    "utils.adata.save_h5ad(adata_corrected, adata_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986639c1",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "settings.close_logfile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sctoolbox",
   "language": "python",
   "name": "sctoolbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "sc_framework": {
   "version": "0.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
